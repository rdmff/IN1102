{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRmPCl4jjASJ",
        "outputId": "ef33f5d8-c269-4c13-89b1-40c93258d4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensões do dataset mfeat-fou: (2000, 76)\n",
            "Dimensões do dataset mfeat-fac: (2000, 216)\n",
            "Dimensões do dataset mfeat-zer: (2000, 47)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Função para carregar os dados de um arquivo de texto\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = np.loadtxt(file)\n",
        "    return data\n",
        "\n",
        "# Carregar os datasets mfeat-fou, mfeat-fac e mfeat-zer\n",
        "mfeat_fou_data = load_data('mfeat-fou')\n",
        "mfeat_fac_data = load_data('mfeat-fac')\n",
        "mfeat_zer_data = load_data('mfeat-zer')\n",
        "\n",
        "#print(mfeat_fou_data)\n",
        "#print(mfeat_fac_data)\n",
        "#print(mfeat_zer_data)\n",
        "\n",
        "# Verificar as dimensões dos datasets carregados\n",
        "print(\"Dimensões do dataset mfeat-fou:\", mfeat_fou_data.shape)\n",
        "print(\"Dimensões do dataset mfeat-fac:\", mfeat_fac_data.shape)\n",
        "print(\"Dimensões do dataset mfeat-zer:\", mfeat_zer_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar as primeiras 100 linhas de cada conjunto de dados\n",
        "data1 = mfeat_fou_data\n",
        "data2 = mfeat_fac_data\n",
        "data3 = mfeat_zer_data"
      ],
      "metadata": {
        "id": "jJsjAcFYlf4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Supondo que 'matriz' seja a sua matriz NumPy\n",
        "np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "t0OVVQEqjzfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "from sklearn.neighbors import KernelDensity, KNeighborsClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ParzenWindowClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, bandwidth=1.0):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.kde_models = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.kde_models = []\n",
        "        for c in self.classes_:\n",
        "            kde = KernelDensity(kernel='gaussian', bandwidth=self.bandwidth)\n",
        "            kde.fit(X[y == c])\n",
        "            self.kde_models.append(kde)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        log_probs = np.array([kde.score_samples(X) for kde in self.kde_models]).T\n",
        "        probs = np.exp(log_probs)\n",
        "        return probs / probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "def majority_vote_classifier(y_pred1, y_pred2, y_pred3):\n",
        "    y_pred_stack = np.vstack((y_pred1, y_pred2, y_pred3)).T\n",
        "    y_pred_final = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=y_pred_stack)\n",
        "    return y_pred_final\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def evaluate_majority_vote_with_cv(classifier, data1, data2, data3, n_clusters=10, n_splits=10, n_repeats=30):\n",
        "    if data1 is None or data2 is None or data3 is None:\n",
        "        raise ValueError(\"One of the input datasets is None.\")\n",
        "    if data1.shape[0] != data2.shape[0] or data1.shape[0] != data3.shape[0]:\n",
        "        raise ValueError(\"All input datasets must have the same number of samples.\")\n",
        "\n",
        "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
        "    results = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "    pseudo_labels1 = create_pseudo_labels(data1, n_clusters)\n",
        "    pseudo_labels2 = create_pseudo_labels(data2, n_clusters)\n",
        "    pseudo_labels3 = create_pseudo_labels(data3, n_clusters)\n",
        "\n",
        "    for train_index, test_index in cv.split(data1, pseudo_labels1):\n",
        "        data1_train, data1_test = data1[train_index], data1[test_index]\n",
        "        data2_train, data2_test = data2[train_index], data2[test_index]\n",
        "        data3_train, data3_test = data3[train_index], data3[test_index]\n",
        "        pseudo_labels1_train, pseudo_labels1_test = pseudo_labels1[train_index], pseudo_labels1[test_index]\n",
        "        pseudo_labels2_train, pseudo_labels2_test = pseudo_labels2[train_index], pseudo_labels2[test_index]\n",
        "        pseudo_labels3_train, pseudo_labels3_test = pseudo_labels3[train_index], pseudo_labels3[test_index]\n",
        "\n",
        "        if classifier == 'GaussianNB':\n",
        "            clf1, clf2, clf3 = GaussianNB(), GaussianNB(), GaussianNB()\n",
        "        elif classifier == 'KNN':\n",
        "            clf1, clf2, clf3 = KNeighborsClassifier(metric='euclidean'), KNeighborsClassifier(metric='euclidean'), KNeighborsClassifier(metric='euclidean')\n",
        "        elif classifier == 'Parzen':\n",
        "            clf1, clf2, clf3 = ParzenWindowClassifier(), ParzenWindowClassifier(), ParzenWindowClassifier()\n",
        "        elif classifier == 'LogisticRegression':\n",
        "            clf1, clf2, clf3 = LogisticRegression(max_iter=1000, multi_class='ovr'), LogisticRegression(max_iter=1000, multi_class='ovr'), LogisticRegression(max_iter=1000, multi_class='ovr')\n",
        "\n",
        "        # Ajuste de hiperparâmetros usando validação cruzada interna (5-fold)\n",
        "        if classifier in ['Parzen', 'KNN']:\n",
        "            param_grid = {'bandwidth': np.linspace(0.1, 2.0, 10)} if classifier == 'Parzen' else {'n_neighbors': range(1, 11)}\n",
        "            inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            gs_clf1 = GridSearchCV(clf1, param_grid, cv=inner_cv).fit(data1_train, pseudo_labels1_train)\n",
        "            gs_clf2 = GridSearchCV(clf2, param_grid, cv=inner_cv).fit(data2_train, pseudo_labels2_train)\n",
        "            gs_clf3 = GridSearchCV(clf3, param_grid, cv=inner_cv).fit(data3_train, pseudo_labels3_train)\n",
        "            clf1, clf2, clf3 = gs_clf1.best_estimator_, gs_clf2.best_estimator_, gs_clf3.best_estimator_\n",
        "\n",
        "        clf1.fit(data1_train, pseudo_labels1_train)\n",
        "        clf2.fit(data2_train, pseudo_labels2_train)\n",
        "        clf3.fit(data3_train, pseudo_labels3_train)\n",
        "\n",
        "        y_pred1 = clf1.predict(data1_test)\n",
        "        y_pred2 = clf2.predict(data2_test)\n",
        "        y_pred3 = clf3.predict(data3_test)\n",
        "        y_pred_final = majority_vote_classifier(y_pred1, y_pred2, y_pred3)\n",
        "\n",
        "        # Aqui estamos calculando métricas usando pseudo_labels_test combinados como y_true\n",
        "        y_true_final = np.concatenate((pseudo_labels1_test, pseudo_labels2_test, pseudo_labels3_test))\n",
        "        y_pred_combined = np.concatenate((y_pred1, y_pred2, y_pred3))\n",
        "        accuracy, precision, recall, f1 = calculate_metrics(y_true_final, y_pred_combined)\n",
        "        results['accuracy'].append(accuracy)\n",
        "        results['precision'].append(precision)\n",
        "        results['recall'].append(recall)\n",
        "        results['f1'].append(f1)\n",
        "\n",
        "    summary = {}\n",
        "    for metric in results:\n",
        "        metric_mean = np.mean(results[metric])\n",
        "        metric_std = np.std(results[metric])\n",
        "        confidence_interval = 1.96 * metric_std / np.sqrt(len(results[metric]))\n",
        "        summary[metric] = (metric_mean, metric_mean - confidence_interval, metric_mean + confidence_interval)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Avaliar o voto majoritário com validação cruzada repetida\n",
        "classifiers = ['GaussianNB', 'KNN', 'Parzen', 'LogisticRegression']\n",
        "data1, data2, data3 = data1, data2, data3\n",
        "for classifier in classifiers:\n",
        "    print(f\"Evaluating majority vote classifier with 30x10 repeated stratified cross-validation for {classifier}...\")\n",
        "    results_majority_vote = evaluate_majority_vote_with_cv(classifier, data1, data2, data3)\n",
        "    print(\"Results:\", results_majority_vote)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp-JTOH_esIh",
        "outputId": "f07ef69a-5c77-43e0-a559-9f4c56d485c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating majority vote classifier with 30x10 repeated stratified cross-validation for GaussianNB...\n",
            "Results: {'accuracy': (0.8824000000000001, 0.8809510853117499, 0.8838489146882502), 'precision': (0.8849557697979403, 0.8835190124539836, 0.8863925271418971), 'recall': (0.8824000000000001, 0.8809510853117499, 0.8838489146882502), 'f1': (0.8822781310409225, 0.8808227551852524, 0.8837335068965925)}\n",
            "\n",
            "Evaluating majority vote classifier with 30x10 repeated stratified cross-validation for KNN...\n",
            "Results: {'accuracy': (0.9243277777777779, 0.9231274193087544, 0.9255281362468013), 'precision': (0.9253384426955306, 0.9241397082196166, 0.9265371771714446), 'recall': (0.9243277777777779, 0.9231274193087544, 0.9255281362468013), 'f1': (0.9240962131433631, 0.9228877083020922, 0.925304717984634)}\n",
            "\n",
            "Evaluating majority vote classifier with 30x10 repeated stratified cross-validation for Parzen...\n",
            "Results: {'accuracy': (0.4524111111111112, 0.4509608784325187, 0.4538613437897037), 'precision': (0.85663315672248, 0.854887317424368, 0.858378996020592), 'recall': (0.4524111111111112, 0.4509608784325187, 0.4538613437897037), 'f1': (0.5259613858853867, 0.5245616524621182, 0.5273611193086551)}\n",
            "\n",
            "Evaluating majority vote classifier with 30x10 repeated stratified cross-validation for LogisticRegression...\n",
            "Results: {'accuracy': (0.931138888888889, 0.9299464229737167, 0.9323313548040613), 'precision': (0.9321546738543648, 0.9309715859171418, 0.9333377617915878), 'recall': (0.931138888888889, 0.9299464229737167, 0.9323313548040613), 'f1': (0.9310286575683298, 0.929832495160362, 0.9322248199762975)}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}