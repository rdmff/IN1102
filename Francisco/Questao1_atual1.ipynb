{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxYK7nGMyrw1",
        "outputId": "f51c78cb-be52-4a98-a6a8-fc9912a6e72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensões do dataset mfeat-fou: (2000, 76)\n",
            "Dimensões do dataset mfeat-fac: (2000, 216)\n",
            "Dimensões do dataset mfeat-zer: (2000, 47)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Função para carregar os dados de um arquivo de texto\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = np.loadtxt(file)\n",
        "    return data\n",
        "\n",
        "# Carregar os datasets mfeat-fou, mfeat-fac e mfeat-zer\n",
        "mfeat_fou_data = load_data('mfeat-fou')\n",
        "mfeat_fac_data = load_data('mfeat-fac')\n",
        "mfeat_zer_data = load_data('mfeat-zer')\n",
        "\n",
        "#print(mfeat_fou_data)\n",
        "#print(mfeat_fac_data)\n",
        "#print(mfeat_zer_data)\n",
        "\n",
        "# Verificar as dimensões dos datasets carregados\n",
        "print(\"Dimensões do dataset mfeat-fou:\", mfeat_fou_data.shape)\n",
        "print(\"Dimensões do dataset mfeat-fac:\", mfeat_fac_data.shape)\n",
        "print(\"Dimensões do dataset mfeat-zer:\", mfeat_zer_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1ZE8XdU04I2N"
      },
      "outputs": [],
      "source": [
        "# Selecionar as primeiras 100 linhas de cada conjunto de dados\n",
        "data1 = mfeat_fou_data\n",
        "data2 = mfeat_fac_data\n",
        "data3 = mfeat_zer_data\n",
        "epsilon=1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ntog0Ac1DbF",
        "outputId": "7e7d9ad1-5d68-453c-9394-4f0e3a8afd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor mínimo para mfeat_fou_data: 0.00017629\n",
            "Valor máximo para mfeat_fou_data: 0.79648722\n",
            "Valor da mediana para mfeat_fou_data: 0.104986425\n",
            "Valor mínimo para mfeat_fac_data: 0.0\n",
            "Valor máximo para mfeat_fac_data: 1353.0\n",
            "Valor da mediana para mfeat_fac_data: 53.0\n",
            "Valor mínimo para mfeat_zer_data: 0.00109432\n",
            "Valor máximo para mfeat_zer_data: 777.86182699\n",
            "Valor da mediana para mfeat_zer_data: 42.03309036\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "min_value1 = np.min(data1)\n",
        "max_value1 = np.max(data1)\n",
        "mean_value1 = np.median(data1)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\"Valor mínimo para mfeat_fou_data:\", min_value1)\n",
        "print(\"Valor máximo para mfeat_fou_data:\", max_value1)\n",
        "print(\"Valor da mediana para mfeat_fou_data:\", mean_value1)\n",
        "\n",
        "min_value2 = np.min(data2)\n",
        "max_value2 = np.max(data2)\n",
        "mean_value2 = np.median(data2)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\"Valor mínimo para mfeat_fac_data:\", min_value2)\n",
        "print(\"Valor máximo para mfeat_fac_data:\", max_value2)\n",
        "print(\"Valor da mediana para mfeat_fac_data:\", mean_value2)\n",
        "\n",
        "min_value3 = np.min(data3)\n",
        "max_value3 = np.max(data3)\n",
        "mean_value3 = np.median(data3)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\"Valor mínimo para mfeat_zer_data:\", min_value3)\n",
        "print(\"Valor máximo para mfeat_zer_data:\", max_value3)\n",
        "print(\"Valor da mediana para mfeat_zer_data:\", mean_value3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4ANPdutEhhJl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Supondo que 'matriz' seja a sua matriz NumPy\n",
        "np.set_printoptions(threshold=np.inf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p42SLEIMH9OX"
      },
      "source": [
        "# **MFEAT-FOU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaqSC2VxG7tW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
        "from scipy.special import comb\n",
        "\n",
        "# Função para calcular o valor do kernel gaussiano de dados com centros de cluster\n",
        "def gaussian_distance(data, centers, s):\n",
        "    gaussian_dist = np.exp(-0.5 * np.sum(((data[:, np.newaxis] - centers) ** 2) / s**2, axis=2))\n",
        "    return gaussian_dist\n",
        "\n",
        "# Função para calcular os graus de pertinência usando o método lagrangeano\n",
        "def update_membership_using_lagrangean(data, centers, s, m):\n",
        "    gaussian_dist = gaussian_distance(data, centers, s)\n",
        "    p = 2 - 2 * gaussian_dist\n",
        "    p = np.fmax(p, np.finfo(np.float64).eps)\n",
        "    p = (1/p) ** (1/(m-1))\n",
        "    u_new = p / np.sum(p, axis=1, keepdims=True)\n",
        "    u_new = np.fmax(u_new, np.finfo(np.float64).eps)\n",
        "    return u_new\n",
        "\n",
        "# Função para calcular os parâmetros de largura global usando o método lagrangeano\n",
        "def update_width_parameters(data, U, gaussian_dist, m, centers):\n",
        "    n_samples, n_features = data.shape\n",
        "    s = np.zeros(n_features)\n",
        "    um = U ** m\n",
        "\n",
        "    for j in range(n_features):\n",
        "        numerator = np.prod([\n",
        "            np.sum([\n",
        "                um[:, i] * gaussian_dist[:, i] * (data[:, h] - centers[i, h])**2\n",
        "                for i in range(len(centers))\n",
        "            ])\n",
        "            for h in range(n_features)\n",
        "        ])**(1/n_features)\n",
        "\n",
        "        denominator = np.sum([\n",
        "            um[:, i] * gaussian_dist[:, i] * (data[:, j] - centers[i, j])**2\n",
        "            for i in range(len(centers))\n",
        "        ])\n",
        "\n",
        "        s[j] = numerator / denominator\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "# Função para calcular o Modified Partition Coefficient (MPC)\n",
        "def calculate_mpc(U):\n",
        "    n_samples, n_clusters = U.shape\n",
        "    mpc = np.sum(U ** 2) / n_samples\n",
        "    return mpc\n",
        "\n",
        "# Função para calcular os centróides\n",
        "def calculate_centers(data, U, m, gaussian_dist, n_clusters):\n",
        "    centers = []\n",
        "    um = U ** m\n",
        "    for n in range(n_clusters):\n",
        "        p = um[:, n].reshape(-1, 1) * gaussian_dist[:, n].reshape(-1, 1)\n",
        "        q = p * data\n",
        "        center_i = np.sum(q, axis=0) / np.sum(p, axis=0)\n",
        "        centers.append(center_i)\n",
        "    centers = np.array(centers)\n",
        "    return centers\n",
        "\n",
        "# Função para calcular J_{KFCM-W.1}\n",
        "def compute_cost(U, m, gaussian_dist):\n",
        "    cost = np.sum((U ** m) * (2 - 2 * gaussian_dist))\n",
        "    return cost\n",
        "\n",
        "# Função principal para executar o algoritmo KFCM-K-W.1\n",
        "def gaussian_kernel_fuzzy_c_means_KW(data, n_clusters, m, max_iters, tol, random_state=None):\n",
        "    # Inicialização dos parâmetros e variáveis\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    n_samples, n_features = data.shape\n",
        "    U = np.random.rand(n_samples, n_clusters)\n",
        "    U /= np.sum(U, axis=1, keepdims=True)\n",
        "    centers = np.random.permutation(data)[:n_clusters]\n",
        "    s = np.ones(n_features)\n",
        "\n",
        "    for iteration in range(max_iters):\n",
        "        # Salva os valores de associação fuzzy antes de atualizar\n",
        "        U_old = U.copy()\n",
        "\n",
        "        # Passo 1: Computa a distância gaussiana\n",
        "        gaussian_dist = gaussian_distance(data, centers, s)\n",
        "\n",
        "        # Passo 2: Atualiza os parâmetros de largura global\n",
        "        s = update_width_parameters(data, U, gaussian_dist, m, centers)\n",
        "\n",
        "        # Passo 3: Atualiza os centróides\n",
        "        centers = update_cluster_prototypes(data, U, gaussian_dist, m)\n",
        "\n",
        "        # Passo 4: Atualiza os valores de associação fuzzy\n",
        "        U = update_membership_using_lagrangean(data, centers, s, m)\n",
        "\n",
        "        # Calcula a diferença e verifica a convergência\n",
        "        diff = np.linalg.norm(U - U_old)\n",
        "        if diff < tol:\n",
        "            break\n",
        "\n",
        "    cost = compute_cost(U, m, gaussian_dist)\n",
        "    return U, centers, s, cost\n",
        "\n",
        "\n",
        "# Função para calcular os protótipos dos clusters fuzzy usando o método lagrangeano\n",
        "def update_cluster_prototypes(data, U, gaussian_dist, m):\n",
        "    n_samples, n_features = data.shape\n",
        "    centers = []\n",
        "    um = U ** m  # Definindo um corretamente\n",
        "\n",
        "    for n in range(n_clusters):\n",
        "        p = um[:, n].reshape(-1, 1) * gaussian_dist[:, n].reshape(-1, 1)\n",
        "        q = p * data\n",
        "        center_i = np.sum(q, axis=0) / np.sum(p, axis=0)\n",
        "        centers.append(center_i)\n",
        "    centers = np.array(centers)\n",
        "    return centers\n",
        "\n",
        "\n",
        "# Função para calcular os vetores de parâmetros de largura de cada grupo\n",
        "def calculate_group_width_parameters(data, U, group_prototypes, m):\n",
        "    s = []\n",
        "    um = U ** m\n",
        "    for i, prototype in enumerate(group_prototypes):\n",
        "        dist = np.sum(um[:, i] * np.linalg.norm(data - prototype, axis=1))\n",
        "        s.append(dist / np.sum(um[:, i]))\n",
        "    return np.array(s)\n",
        "\n",
        "# Função para criar a partição crisp baseada nos valores de pertinência\n",
        "def create_crisp_partition1(U):\n",
        "    return np.argmax(U, axis=1)\n",
        "\n",
        "# Função para calcular o ARI\n",
        "def calculate_ari(labels_true, labels_pred):\n",
        "    return adjusted_rand_score(labels_true, labels_pred)\n",
        "\n",
        "# Definir parâmetros\n",
        "n_clusters = 10  # Número de clusters\n",
        "m = 1.6  # Parâmetro de fuzziness\n",
        "max_iters = 100  # Número máximo de iterações\n",
        "tol = 1e-6  # Tolerância para a convergência\n",
        "n_runs = 50  # Número de execuções\n",
        "\n",
        "# Executar o algoritmo para o dataset data1\n",
        "best_cost = float('inf')\n",
        "best_U, best_centers, best_s = None, None, None\n",
        "\n",
        "for run in range(n_runs):\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data1, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    if cost < best_cost:\n",
        "        best_cost = cost\n",
        "        best_U = U\n",
        "        best_centers = centers\n",
        "        best_s = s\n",
        "\n",
        "# Verificar se um resultado válido foi encontrado\n",
        "if best_U is None:\n",
        "    print(\"\\nNão foi possível encontrar uma solução válida para o dataset data1.\")\n",
        "else:\n",
        "    # Calcular os protótipos de cada grupo\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data1, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    gaussian_dist = gaussian_distance(data1, centers, s)  # Capturar a distância gaussiana\n",
        "    group_prototypes = update_cluster_prototypes(data1, best_U, gaussian_dist, m)  # Passar gaussian_dist aqui\n",
        "\n",
        "    # Calcular os vetores de parâmetros de largura de cada grupo\n",
        "    group_width_parameters = calculate_group_width_parameters(data1, best_U, group_prototypes, m)\n",
        "\n",
        "    # Criar a partição crisp\n",
        "    crisp_partition1 = create_crisp_partition1(best_U)\n",
        "\n",
        "    # Calcular o Modified Partition Coefficient (MPC)\n",
        "    mpc = calculate_mpc(best_U)\n",
        "\n",
        "    # Calcular o ARI entre duas execuções diferentes do algoritmo (não supervisionado)\n",
        "    # Executar uma segunda vez para obter outra partição dos clusters\n",
        "    U2, centers2, s2, cost2 = gaussian_kernel_fuzzy_c_means_KW(data1, n_clusters, m, max_iters, tol, random_state=n_runs)\n",
        "    class_cluster_list2 = create_crisp_partition1(U2)\n",
        "\n",
        "    # Calcular o ARI\n",
        "    ari = calculate_ari(crisp_partition1, class_cluster_list2)\n",
        "\n",
        "    # Calcular a matriz de confusão entre a partição crisp e a partição a priori\n",
        "    confusion_mat = confusion_matrix(crisp_partition1, class_cluster_list2)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(\"\\nResultados para o dataset mfeat-fou:\")\n",
        "    print(\"Melhor valor da função objetivo:\", best_cost)\n",
        "    print(\"Melhores centróides do cluster:\")\n",
        "    print(best_centers)\n",
        "    print(\"Melhores parâmetros de largura global:\")\n",
        "    print(best_s)\n",
        "    print(\"Modified Partition Coefficient (MPC):\", mpc)\n",
        "    print(\"Índice de Rand corrigido (ARI):\", ari)\n",
        "    print(\"Matriz de confusão entre a partição crisp e a primeira execução:\")\n",
        "    print(confusion_mat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JLGupBFL33b"
      },
      "source": [
        "# **MFEAT-FAC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOW3Otf1ajDY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
        "from scipy.special import comb\n",
        "\n",
        "# Função para calcular o valor do kernel gaussiano de dados com centros de cluster\n",
        "def gaussian_distance(data, centers, s):\n",
        "    gaussian_dist = np.exp(-0.5 * np.sum(((data[:, np.newaxis] - centers) ** 2) / (s**2+epsilon), axis=2))\n",
        "    return gaussian_dist\n",
        "\n",
        "# Função para calcular os graus de pertinência usando o método lagrangeano\n",
        "def update_membership_using_lagrangean(data, centers, s, m):\n",
        "    gaussian_dist = gaussian_distance(data, centers, s)\n",
        "    p = 2 - 2 * gaussian_dist\n",
        "    p = np.fmax(p, np.finfo(np.float64).eps)\n",
        "    p = (1/p) ** (1/(m-1))\n",
        "    u_new = p / np.sum(p, axis=1, keepdims=True)\n",
        "    u_new = np.fmax(u_new, np.finfo(np.float64).eps)\n",
        "    return u_new\n",
        "\n",
        "# Função para calcular os parâmetros de largura global usando o método lagrangeano\n",
        "def update_width_parameters(data, U, gaussian_dist, m, centers):\n",
        "    n_samples, n_features = data.shape\n",
        "    s = np.zeros(n_features)\n",
        "    um = U ** m\n",
        "    epsilon = 1e-6  # Definindo epsilon antes de usá-lo\n",
        "\n",
        "    for j in range(n_features):\n",
        "        numerator = np.sum([\n",
        "            np.sum([\n",
        "                um[:, i] * gaussian_dist[:, i] * np.sum((data[:, j] - centers[i][j])**2)\n",
        "                for i in range(len(centers))\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        denominator = np.sum([\n",
        "            np.sum([\n",
        "                um[:, i] * gaussian_dist[:, i]\n",
        "                for i in range(len(centers))\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        s[j] = numerator / (denominator + epsilon)  # Adiciona epsilon ao denominador\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "# Função para calcular os centróides\n",
        "def update_cluster_prototypes(data, U, gaussian_dist, m):\n",
        "    n_samples, n_features = data.shape\n",
        "    centers = []\n",
        "    um = U ** m\n",
        "\n",
        "    for n in range(len(um[0])):\n",
        "        um_sum = np.sum(um[:, n])\n",
        "        center_n = np.sum(data * um[:, n].reshape(-1, 1), axis=0) / um_sum\n",
        "        centers.append(center_n)\n",
        "\n",
        "    return np.array(centers)\n",
        "\n",
        "# Função para calcular J_{KFCM-W.1}\n",
        "def compute_cost(U, m, gaussian_dist):\n",
        "    cost = np.sum((U ** m) * (2 - 2 * gaussian_dist))\n",
        "    return cost\n",
        "\n",
        "# Função principal para executar o algoritmo KFCM-K-W.1\n",
        "def gaussian_kernel_fuzzy_c_means_KW(data, n_clusters, m, max_iters, tol, random_state=None):\n",
        "    # Inicialização dos parâmetros e variáveis\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    n_samples, n_features = data.shape\n",
        "    U = np.random.rand(n_samples, n_clusters)\n",
        "    U /= np.sum(U, axis=1, keepdims=True)\n",
        "    um = U ** m  # Definição correta de um\n",
        "    centers = np.random.permutation(data)[:n_clusters]\n",
        "    s = np.ones(n_features)\n",
        "\n",
        "    for iteration in range(max_iters):\n",
        "        # Salva os valores de associação fuzzy antes de atualizar\n",
        "        U_old = U.copy()\n",
        "\n",
        "        # Passo 1: Computa a distância gaussiana\n",
        "        gaussian_dist = gaussian_distance(data, centers, s)\n",
        "\n",
        "        # Passo 2: Atualiza os parâmetros de largura global\n",
        "        s = update_width_parameters(data, U, gaussian_dist, m, centers)\n",
        "\n",
        "        # Passo 3: Atualiza os centróides\n",
        "        centers = update_cluster_prototypes(data, U, gaussian_dist, m)\n",
        "\n",
        "        # Passo 4: Atualiza os valores de associação fuzzy\n",
        "        U = update_membership_using_lagrangean(data, centers, s, m)\n",
        "\n",
        "        # Calcula a diferença e verifica a convergência\n",
        "        diff = np.linalg.norm(U - U_old)\n",
        "        if diff < tol:\n",
        "            break\n",
        "\n",
        "    cost = compute_cost(U, m, gaussian_dist)\n",
        "    return U, centers, s, cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Função para calcular o Modified Partition Coefficient (MPC)\n",
        "def calculate_mpc(U):\n",
        "    n_samples, n_clusters = U.shape\n",
        "    mpc = np.sum(U ** 2) / n_samples\n",
        "    return mpc\n",
        "\n",
        "# Função para calcular o ARI\n",
        "def calculate_ari(labels_true, labels_pred):\n",
        "    return adjusted_rand_score(labels_true, labels_pred)\n",
        "\n",
        "# Definir parâmetros\n",
        "n_clusters = 10  # Número de clusters\n",
        "m = 1.6  # Parâmetro de fuzziness\n",
        "max_iters = 100  # Número máximo de iterações\n",
        "tol = 1e-6  # Tolerância para a convergência\n",
        "n_runs = 50  # Número de execuções\n",
        "\n",
        "# Executar o algoritmo para o dataset data2\n",
        "best_cost = float('inf')\n",
        "best_U, best_centers, best_s = None, None, None\n",
        "\n",
        "for run in range(n_runs):\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data2, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    if cost < best_cost:\n",
        "        best_cost = cost\n",
        "        best_U = U\n",
        "        best_centers = centers\n",
        "        best_s = s\n",
        "\n",
        "# Verificar se um resultado válido foi encontrado\n",
        "if best_U is None:\n",
        "    print(\"\\nNão foi possível encontrar uma solução válida para o dataset data2.\")\n",
        "else:\n",
        "    # Calcular os protótipos de cada grupo\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data2, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    gaussian_dist = gaussian_distance(data2, centers, s)  # Capturar a distância gaussiana\n",
        "\n",
        "    # Criar a partição crisp\n",
        "    crisp_partition = np.argmax(best_U, axis=1)\n",
        "\n",
        "    # Calcular o Modified Partition Coefficient (MPC)\n",
        "    mpc = calculate_mpc(best_U)\n",
        "\n",
        "    # Calcular o ARI entre duas execuções diferentes do algoritmo (não supervisionado)\n",
        "    # Executar uma segunda vez para obter outra partição dos clusters\n",
        "    U2, _, _, _ = gaussian_kernel_fuzzy_c_means_KW(data2, n_clusters, m, max_iters, tol, random_state=n_runs)\n",
        "    class_cluster_list2 = np.argmax(U2, axis=1)\n",
        "\n",
        "    # Calcular o ARI\n",
        "    ari = calculate_ari(crisp_partition, class_cluster_list2)\n",
        "\n",
        "    # Calcular a matriz de confusão entre a partição crisp e a partição a priori\n",
        "    confusion_mat = confusion_matrix(crisp_partition, class_cluster_list2)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(\"\\nResultados para o dataset mfeat-fac:\")\n",
        "    print(\"Melhor valor da função objetivo:\", best_cost)\n",
        "    print(\"Melhores centróides do cluster:\")\n",
        "    print(best_centers)\n",
        "    print(\"Melhores parâmetros de largura global:\")\n",
        "    print(best_s)\n",
        "    print(\"Modified Partition Coefficient (MPC):\", mpc)\n",
        "    print(\"Índice de Rand corrigido (ARI):\", ari)\n",
        "    print(\"Matriz de confusão entre a partição crisp e a primeira execução:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NSqtOPweEk5"
      },
      "source": [
        "# **MFEAT-ZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYiScfVCeJAs",
        "outputId": "797ebe84-bc78-4a34-ddce-7eb6eb2c8892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados para o dataset mfeat-zer:\n",
            "Melhor valor da função objetivo: 0.044898231460363675\n",
            "Melhores centróides do cluster:\n",
            "[[8.24790437e-02 1.83779619e+00 2.40739406e+01 7.76289278e+01\n",
            "  1.12627852e+02 2.33331666e+02 1.48296635e+02 1.68053978e-01\n",
            "  3.59266133e+00 2.70306483e+01 9.64068192e+01 1.25515920e+02\n",
            "  1.34705618e+02 2.24565020e-01 7.15869059e+00 4.51957860e+01\n",
            "  1.09253195e+02 1.51282885e+02 1.06511837e+02 4.70877679e-01\n",
            "  8.78037787e+00 6.18926262e+01 1.23109821e+02 1.30296004e+02\n",
            "  1.01820382e+00 1.63219782e+01 8.05301374e+01 2.08759690e+02\n",
            "  1.14658761e+02 1.36371460e+00 2.48219966e+01 9.75644797e+01\n",
            "  1.26698026e+02 2.79782145e+00 3.65312270e+01 2.70291710e+02\n",
            "  1.25595417e+02 4.71045294e+00 5.03155850e+01 1.27257685e+02\n",
            "  7.76011478e+00 1.82960195e+02 4.02190198e+02 1.22888981e+01\n",
            "  9.36297899e+01 5.36874407e+01 5.01464161e+02]\n",
            " [4.18696828e-02 1.51585304e+00 2.04234393e+01 6.68792281e+01\n",
            "  1.10937022e+02 2.64915807e+02 1.35779327e+02 1.09908842e-01\n",
            "  2.63577953e+00 2.31308901e+01 8.86257376e+01 1.31329045e+02\n",
            "  1.28184192e+02 1.81317699e-01 5.90855597e+00 3.66212072e+01\n",
            "  1.00060144e+02 1.57457436e+02 1.18358438e+02 3.37452495e-01\n",
            "  7.29569358e+00 5.42606276e+01 1.15361459e+02 1.28323231e+02\n",
            "  8.23109597e-01 1.26890627e+01 7.41619072e+01 1.92718830e+02\n",
            "  1.37999741e+02 1.10678759e+00 2.09783117e+01 8.48376476e+01\n",
            "  1.17488240e+02 2.11449867e+00 3.40929909e+01 2.63982871e+02\n",
            "  1.29620285e+02 3.88119728e+00 4.21338745e+01 1.17665050e+02\n",
            "  7.27708982e+00 1.80444211e+02 4.15225841e+02 1.01160520e+01\n",
            "  8.91704120e+01 5.29985535e+01 5.16833914e+02]\n",
            " [3.90660741e-02 1.34714577e+00 1.74219320e+01 5.94555861e+01\n",
            "  1.02455871e+02 2.80131663e+02 1.27642765e+02 8.61082984e-02\n",
            "  2.36534746e+00 2.27218789e+01 8.52111488e+01 1.36380006e+02\n",
            "  1.29601820e+02 1.59794393e-01 4.99883331e+00 3.19438446e+01\n",
            "  9.16422567e+01 1.56583762e+02 1.19893605e+02 2.99596294e-01\n",
            "  7.06910748e+00 5.05466929e+01 1.09887153e+02 1.25201590e+02\n",
            "  6.92238019e-01 1.09380533e+01 6.95491447e+01 1.85378599e+02\n",
            "  1.42958894e+02 1.06159455e+00 1.91089730e+01 7.48262356e+01\n",
            "  1.08337710e+02 1.80845342e+00 3.23377017e+01 2.59736009e+02\n",
            "  1.21061477e+02 3.48221221e+00 3.59825401e+01 1.15880621e+02\n",
            "  6.94577953e+00 1.78194835e+02 4.13791236e+02 8.56878169e+00\n",
            "  9.16502214e+01 5.23456152e+01 5.17417781e+02]\n",
            " [1.27302124e-01 2.53495298e+00 2.78355544e+01 8.05504563e+01\n",
            "  1.13295681e+02 2.17438450e+02 1.60239164e+02 1.75014206e-01\n",
            "  3.59889657e+00 3.05313528e+01 9.59486269e+01 1.32718919e+02\n",
            "  1.50677135e+02 3.14047817e-01 8.50008978e+00 4.97012274e+01\n",
            "  1.17321342e+02 1.43856989e+02 1.07512806e+02 4.82434037e-01\n",
            "  1.01753115e+01 6.12334509e+01 1.18479214e+02 1.40444618e+02\n",
            "  1.23333627e+00 1.86955362e+01 8.88395184e+01 2.19766211e+02\n",
            "  1.09780274e+02 1.61329464e+00 2.47099505e+01 9.08144692e+01\n",
            "  1.20684820e+02 3.29686788e+00 4.10339229e+01 2.90660589e+02\n",
            "  1.12753311e+02 4.73741292e+00 4.68576249e+01 1.15241260e+02\n",
            "  8.82449138e+00 1.98732480e+02 3.80091875e+02 1.15088929e+01\n",
            "  8.74859926e+01 5.87007152e+01 4.93535010e+02]\n",
            " [2.15819757e-01 3.20129617e+00 3.42873485e+01 1.01761786e+02\n",
            "  1.31657332e+02 1.71764844e+02 1.86703639e+02 2.52149805e-01\n",
            "  4.22223078e+00 4.30376302e+01 1.16185144e+02 1.27879186e+02\n",
            "  1.44919850e+02 4.01844741e-01 1.08290421e+01 6.67220430e+01\n",
            "  1.42868774e+02 1.27161009e+02 1.21716988e+02 5.76669896e-01\n",
            "  1.47627593e+01 7.79822028e+01 1.08124614e+02 1.70206640e+02\n",
            "  1.61183534e+00 2.60669563e+01 1.04943278e+02 2.23363015e+02\n",
            "  9.05424019e+01 2.38644465e+00 3.23811029e+01 8.06214042e+01\n",
            "  1.43851619e+02 4.71309700e+00 4.72355071e+01 2.96952643e+02\n",
            "  1.01748174e+02 6.31699887e+00 4.21050385e+01 1.29371607e+02\n",
            "  1.00048387e+01 2.05738386e+02 3.32569611e+02 1.05423012e+01\n",
            "  1.11735343e+02 6.14218217e+01 4.52925568e+02]\n",
            " [9.57171942e-02 2.42321996e+00 2.74861099e+01 7.49330574e+01\n",
            "  1.10863954e+02 2.63610566e+02 1.69777737e+02 8.96702629e-02\n",
            "  2.50913000e+00 2.34281146e+01 7.39288526e+01 1.21847048e+02\n",
            "  1.31955067e+02 2.92761897e-01 8.10128320e+00 4.38646908e+01\n",
            "  1.06395587e+02 1.67904819e+02 1.02237964e+02 3.27228821e-01\n",
            "  7.56771361e+00 4.43825669e+01 1.06250926e+02 1.17209939e+02\n",
            "  1.14490433e+00 1.59771118e+01 8.33942746e+01 2.11537798e+02\n",
            "  1.21445016e+02 1.17070372e+00 1.71939290e+01 7.64222067e+01\n",
            "  1.03468919e+02 2.75602016e+00 3.93860736e+01 2.84978308e+02\n",
            "  1.06771478e+02 3.21018142e+00 3.72754511e+01 1.01678201e+02\n",
            "  8.54928627e+00 1.96283489e+02 3.80924856e+02 8.80972730e+00\n",
            "  7.46297233e+01 5.80486400e+01 4.97075140e+02]\n",
            " [1.56984341e-01 2.53981590e+00 3.06487972e+01 9.40269950e+01\n",
            "  1.18515541e+02 1.99931217e+02 1.64310164e+02 2.23457878e-01\n",
            "  3.96952208e+00 3.53939359e+01 1.06432469e+02 1.29203721e+02\n",
            "  1.49518982e+02 3.17677330e-01 9.47285989e+00 5.90907232e+01\n",
            "  1.23261582e+02 1.41077500e+02 1.12314152e+02 5.37256813e-01\n",
            "  1.19639364e+01 7.06262002e+01 1.13408515e+02 1.60896894e+02\n",
            "  1.38766623e+00 2.24632410e+01 9.06291928e+01 2.24849299e+02\n",
            "  1.03878141e+02 1.91370813e+00 2.91301444e+01 9.01726750e+01\n",
            "  1.41747779e+02 3.98817084e+00 4.10385360e+01 2.93337841e+02\n",
            "  1.05313542e+02 5.65096917e+00 4.79356010e+01 1.27256435e+02\n",
            "  8.73021081e+00 2.00464943e+02 3.59807306e+02 1.19680231e+01\n",
            "  9.96059458e+01 5.93136866e+01 4.77283934e+02]\n",
            " [2.09590374e-01 2.66523671e+00 3.41209507e+01 1.02928044e+02\n",
            "  1.27894820e+02 1.83460955e+02 1.80907140e+02 2.64026481e-01\n",
            "  4.22634799e+00 4.41597117e+01 1.19071887e+02 1.30172136e+02\n",
            "  1.46852231e+02 3.34743914e-01 1.07587010e+01 6.73639673e+01\n",
            "  1.34446577e+02 1.30740583e+02 1.17822506e+02 5.75998557e-01\n",
            "  1.51789037e+01 8.06700335e+01 1.12457920e+02 1.75226305e+02\n",
            "  1.59925272e+00 2.62875196e+01 9.64654532e+01 2.22580796e+02\n",
            "  9.70153654e+01 2.45559340e+00 3.36380458e+01 8.59332074e+01\n",
            "  1.48190447e+02 4.74964175e+00 4.27231669e+01 3.00480090e+02\n",
            "  9.34483770e+01 6.57418635e+00 4.51583605e+01 1.33398588e+02\n",
            "  8.95094802e+00 2.08947783e+02 3.22855367e+02 1.12928027e+01\n",
            "  1.17188399e+02 6.24356566e+01 4.53247223e+02]\n",
            " [7.16479354e-02 2.05823914e+00 2.43533421e+01 7.13119617e+01\n",
            "  1.07721727e+02 2.78597899e+02 1.45852391e+02 8.98331989e-02\n",
            "  2.27634233e+00 2.14770642e+01 7.57420215e+01 1.16450196e+02\n",
            "  1.30463859e+02 2.46485876e-01 7.09609778e+00 4.02775826e+01\n",
            "  9.92956487e+01 1.68519120e+02 1.14858398e+02 2.95004890e-01\n",
            "  6.87630216e+00 4.59772254e+01 1.01968439e+02 1.19638313e+02\n",
            "  9.93970062e-01 1.42976385e+01 7.73512820e+01 2.01449563e+02\n",
            "  1.43313268e+02 1.05625007e+00 1.78177858e+01 7.47233403e+01\n",
            "  1.09144035e+02 2.42302626e+00 3.64692826e+01 2.79256588e+02\n",
            "  1.01699487e+02 3.31473737e+00 3.69198473e+01 1.05868596e+02\n",
            "  7.90398198e+00 1.92462963e+02 3.88723610e+02 8.80217290e+00\n",
            "  7.71382733e+01 5.67993589e+01 5.06285316e+02]\n",
            " [2.64765540e-02 9.12379380e-01 1.19681127e+01 4.97132623e+01\n",
            "  9.92310115e+01 3.30596944e+02 1.32668493e+02 4.27998536e-02\n",
            "  1.34094431e+00 1.53263273e+01 6.40407836e+01 1.10711795e+02\n",
            "  1.06358464e+02 1.06112209e-01 3.31665140e+00 2.51707154e+01\n",
            "  7.15077698e+01 1.58678374e+02 1.77082848e+02 1.67393101e-01\n",
            "  4.67768327e+00 3.67374703e+01 8.70457058e+01 1.03768673e+02\n",
            "  4.47882511e-01 8.32198367e+00 5.59360981e+01 1.62380470e+02\n",
            "  1.85635592e+02 6.92210985e-01 1.35634531e+01 5.81804414e+01\n",
            "  9.11964280e+01 1.34633855e+00 2.74120282e+01 2.46837308e+02\n",
            "  1.14646251e+02 2.43134430e+00 2.72121758e+01 9.48018172e+01\n",
            "  6.05950816e+00 1.70488572e+02 4.35902607e+02 6.32310786e+00\n",
            "  7.26655528e+01 4.99851711e+01 5.42313943e+02]]\n",
            "Melhores parâmetros de largura global:\n",
            "[1.33491493e+01 3.36281451e+03 3.55153283e+05 3.33648462e+06\n",
            " 5.78122907e+06 3.45685186e+07 2.06066436e+07 2.16303844e+01\n",
            " 6.67556318e+03 6.82512095e+05 5.78052953e+06 8.52845446e+06\n",
            " 9.46826359e+06 5.37150102e+01 3.46085347e+04 1.29049291e+06\n",
            " 6.77517442e+06 1.13533177e+07 2.81073286e+07 1.24268535e+02\n",
            " 7.88834761e+04 2.38253881e+06 7.75429566e+06 9.43806801e+06\n",
            " 7.60086232e+02 1.89445818e+05 3.50389490e+06 1.24233525e+07\n",
            " 2.64244983e+07 2.04593415e+03 3.87580493e+05 5.62665597e+06\n",
            " 8.77918776e+06 6.11199815e+03 6.78486761e+05 7.92220422e+06\n",
            " 1.68190563e+07 1.42735833e+04 1.62441846e+06 8.69085940e+06\n",
            " 3.01743787e+04 3.08518475e+06 1.99411416e+07 9.88025149e+04\n",
            " 5.57001701e+06 2.71681246e+05 1.10615462e+07]\n",
            "Modified Partition Coefficient (MPC): 0.7385522957844798\n",
            "Índice de Rand corrigido (ARI): 0.3934578675888315\n",
            "Matriz de confusão entre a partição crisp e a primeira execução:\n",
            "[[  0   5   0 134   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0  89   0   0   0 112]\n",
            " [  0   0   0   0  54   1   0  45   0 161]\n",
            " [ 47  70   0  26   0   0   0   0   6   0]\n",
            " [  0   0  31   0   0   0  10   0  35   0]\n",
            " [ 80   1   0   0   0  83   0   0   0  10]\n",
            " [  1  37  18  25   0   0  24   0  15   0]\n",
            " [  0   0  54   0   0   0  21   0   0   0]\n",
            " [  0   0   0   0   0  94   0   3   0 102]\n",
            " [  0   0   0   0 304   0   0 198   0   0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
        "from scipy.special import comb\n",
        "\n",
        "# Função para calcular o valor do kernel gaussiano de dados com centros de cluster\n",
        "def gaussian_distance(data, centers, s):\n",
        "    gaussian_dist = np.exp(-0.5 * np.sum(((data[:, np.newaxis] - centers) ** 2) / (s**2+epsilon), axis=2))\n",
        "    return gaussian_dist\n",
        "\n",
        "# Função para calcular os graus de pertinência usando o método lagrangeano\n",
        "def update_membership_using_lagrangean(data, centers, s, m):\n",
        "    gaussian_dist = gaussian_distance(data, centers, s)\n",
        "    p = 2 - 2 * gaussian_dist\n",
        "    p = np.fmax(p, np.finfo(np.float64).eps)\n",
        "    p = (1/p) ** (1/(m-1))\n",
        "    u_new = p / np.sum(p, axis=1, keepdims=True)\n",
        "    u_new = np.fmax(u_new, np.finfo(np.float64).eps)\n",
        "    return u_new\n",
        "\n",
        "# Função para calcular os parâmetros de largura global usando o método lagrangeano\n",
        "def update_width_parameters(data, U, gaussian_dist, m, centers):\n",
        "    n_samples, n_features = data.shape\n",
        "    s = np.zeros(n_features)\n",
        "    um = U ** m\n",
        "    epsilon = 1e-6  # Definindo epsilon antes de usá-lo\n",
        "\n",
        "    for j in range(n_features):\n",
        "        numerator = np.sum([\n",
        "            np.sum([\n",
        "                um[:, i] * gaussian_dist[:, i] * np.sum((data[:, j] - centers[i][j])**2)\n",
        "                for i in range(len(centers))\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        denominator = np.sum([\n",
        "            np.sum([\n",
        "                um[:, i] * gaussian_dist[:, i]\n",
        "                for i in range(len(centers))\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        s[j] = numerator / (denominator + epsilon)  # Adiciona epsilon ao denominador\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "# Função para calcular os centróides\n",
        "def update_cluster_prototypes(data, U, gaussian_dist, m):\n",
        "    n_samples, n_features = data.shape\n",
        "    centers = []\n",
        "    um = U ** m\n",
        "\n",
        "    for n in range(len(um[0])):\n",
        "        um_sum = np.sum(um[:, n])\n",
        "        center_n = np.sum(data * um[:, n].reshape(-1, 1), axis=0) / um_sum\n",
        "        centers.append(center_n)\n",
        "\n",
        "    return np.array(centers)\n",
        "\n",
        "# Função para calcular J_{KFCM-W.1}\n",
        "def compute_cost(U, m, gaussian_dist):\n",
        "    cost = np.sum((U ** m) * (2 - 2 * gaussian_dist))\n",
        "    return cost\n",
        "\n",
        "# Função principal para executar o algoritmo KFCM-K-W.1\n",
        "def gaussian_kernel_fuzzy_c_means_KW(data, n_clusters, m, max_iters, tol, random_state=None):\n",
        "    # Inicialização dos parâmetros e variáveis\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    n_samples, n_features = data.shape\n",
        "    U = np.random.rand(n_samples, n_clusters)\n",
        "    U /= np.sum(U, axis=1, keepdims=True)\n",
        "    um = U ** m  # Definição correta de um\n",
        "    centers = np.random.permutation(data)[:n_clusters]\n",
        "    s = np.ones(n_features)\n",
        "\n",
        "    for iteration in range(max_iters):\n",
        "        # Salva os valores de associação fuzzy antes de atualizar\n",
        "        U_old = U.copy()\n",
        "\n",
        "        # Passo 1: Computa a distância gaussiana\n",
        "        gaussian_dist = gaussian_distance(data, centers, s)\n",
        "\n",
        "        # Passo 2: Atualiza os parâmetros de largura global\n",
        "        s = update_width_parameters(data, U, gaussian_dist, m, centers)\n",
        "\n",
        "        # Passo 3: Atualiza os centróides\n",
        "        centers = update_cluster_prototypes(data, U, gaussian_dist, m)\n",
        "\n",
        "        # Passo 4: Atualiza os valores de associação fuzzy\n",
        "        U = update_membership_using_lagrangean(data, centers, s, m)\n",
        "\n",
        "        # Calcula a diferença e verifica a convergência\n",
        "        diff = np.linalg.norm(U - U_old)\n",
        "        if diff < tol:\n",
        "            break\n",
        "\n",
        "    cost = compute_cost(U, m, gaussian_dist)\n",
        "    return U, centers, s, cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Função para calcular o Modified Partition Coefficient (MPC)\n",
        "def calculate_mpc(U):\n",
        "    n_samples, n_clusters = U.shape\n",
        "    mpc = np.sum(U ** 2) / n_samples\n",
        "    return mpc\n",
        "\n",
        "# Função para calcular o ARI\n",
        "def calculate_ari(labels_true, labels_pred):\n",
        "    return adjusted_rand_score(labels_true, labels_pred)\n",
        "\n",
        "# Definir parâmetros\n",
        "n_clusters = 10  # Número de clusters\n",
        "m = 1.6  # Parâmetro de fuzziness\n",
        "max_iters = 100  # Número máximo de iterações\n",
        "tol = 1e-6  # Tolerância para a convergência\n",
        "n_runs = 50  # Número de execuções\n",
        "\n",
        "# Executar o algoritmo para o dataset data2\n",
        "best_cost = float('inf')\n",
        "best_U, best_centers, best_s = None, None, None\n",
        "\n",
        "for run in range(n_runs):\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data3, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    if cost < best_cost:\n",
        "        best_cost = cost\n",
        "        best_U = U\n",
        "        best_centers = centers\n",
        "        best_s = s\n",
        "\n",
        "# Verificar se um resultado válido foi encontrado\n",
        "if best_U is None:\n",
        "    print(\"\\nNão foi possível encontrar uma solução válida para o dataset data2.\")\n",
        "else:\n",
        "    # Calcular os protótipos de cada grupo\n",
        "    U, centers, s, cost = gaussian_kernel_fuzzy_c_means_KW(data3, n_clusters, m, max_iters, tol, random_state=run)\n",
        "    gaussian_dist = gaussian_distance(data3, centers, s)  # Capturar a distância gaussiana\n",
        "\n",
        "    # Criar a partição crisp\n",
        "    crisp_partition = np.argmax(best_U, axis=1)\n",
        "\n",
        "    # Calcular o Modified Partition Coefficient (MPC)\n",
        "    mpc = calculate_mpc(best_U)\n",
        "\n",
        "    # Calcular o ARI entre duas execuções diferentes do algoritmo (não supervisionado)\n",
        "    # Executar uma segunda vez para obter outra partição dos clusters\n",
        "    U2, _, _, _ = gaussian_kernel_fuzzy_c_means_KW(data3, n_clusters, m, max_iters, tol, random_state=n_runs)\n",
        "    class_cluster_list2 = np.argmax(U2, axis=1)\n",
        "\n",
        "    # Calcular o ARI\n",
        "    ari = calculate_ari(crisp_partition, class_cluster_list2)\n",
        "\n",
        "    # Calcular a matriz de confusão entre a partição crisp e a partição a priori\n",
        "    confusion_mat = confusion_matrix(crisp_partition, class_cluster_list2)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(\"\\nResultados para o dataset mfeat-zer:\")\n",
        "    print(\"Melhor valor da função objetivo:\", best_cost)\n",
        "    print(\"Melhores centróides do cluster:\")\n",
        "    print(best_centers)\n",
        "    print(\"Melhores parâmetros de largura global:\")\n",
        "    print(best_s)\n",
        "    print(\"Modified Partition Coefficient (MPC):\", mpc)\n",
        "    print(\"Índice de Rand corrigido (ARI):\", ari)\n",
        "    print(\"Matriz de confusão entre a partição crisp e a primeira execução:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOVAS TENTATIVAS**"
      ],
      "metadata": {
        "id": "mqAtZ_3dW1Mi"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}